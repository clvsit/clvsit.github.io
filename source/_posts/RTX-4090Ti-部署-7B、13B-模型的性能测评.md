---
title: RTX 4090Ti 部署 7B、13B 模型的性能测评
date: 2023-11-06 13:48:20
tags:
---

## 推理速度测评
实验参数：
- batch_size: 1
- avg num input tokens: 1719.29
- stream: False
- 预测⽅式：接⼝预测

测试结果：
推理框架 | 模型 | TP（模型并⾏） | Throughput（token/s）| avg num output tokens
---|---|---|---|---
vllm | vicuna-7b-v1.5 | 1 | 53.02 | 122.31
vllm | vicuna-7b-v1.5 | 2 | 40.09 | 121.74
vllm | vicuna-13b-v1.3 | 2 | 32.77 | 160.15

## 动态 batching 测评
测试⽅式：借助 ApiFox ⼯具的⾃动化测试，循环 10 轮，每轮启动 3 个线程来调⽤模型服务。

workers | 总耗时(秒) | 接⼝请求耗时(秒) | 平均接⼝请求耗时(毫秒)
---|---|---|---
1 x RTX4090 vicuna-7b-v1.5
1 | 132.325 | 129.96 | 4332
2 | 89.52 | 83.1 | 2770
3 | 70.938 | 63.93 | 2131
2 x RTX4090 vicuna-13b-v1.5
1 | 200.638 | 198.78 | 6626
2 | 113.198 | 106.26 | 3542
3 | 95.591 | 83.25 | 2775
4 x RTX4090 vicuna-13b-v1.5
1 | 252.859 | 250.86 | 8362
2 | 145.762 | 143.28 | 4776
3 | 125.113 | 122.49 | 4083
1 X A100 vicuna-7b-v1.5
1 | 128.601 | 124.8 | 4160
2 | 77.334 | 67.89 | 2263
3 | 65.931 | 52.77 | 1759
1 X A100 vicuna-13b-v1.5
1 | 146.562 | 144.36 | 4812
2 | 79.535 | 75.09 | 2503
3 | 78.642 | 67.32 | 2244

## 测评结论
- vLLM 多卡部署模型的 throughput、接⼝请求耗时都有明显下降，推测是进程间通信的开销，张量
并⾏越多，下降得约为明显。同样都是单卡部署 vicuna-7b-v1.5，A100 相⽐ RTX4090 的提升并没
有特别明显。
- RTX4090 的显存有限，半精度部署 13B 模型⾄少得⽤ 2 张卡进⾏部署，进程间通信的开销不可避
免。相⽐ A100，接⼝调⽤的时延没有明显增加，加上流式输出，对于⽤⼾的体验不会有太⼤的影
响。