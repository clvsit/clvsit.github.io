---
title: RAG 概述
date: 2024-04-04 00:08:23
tags:
category:
- RAG
---


检索增强 LLM（Retrieval Augmented LLM），简单来说，给 LLM 提供外部数据库，对于用户问题（Query），通过一些信息检索（Information Retrieval，IR）的技术，先从外部数据库中检索出和用户问题相关的信息，然后让 LLM 结合这些相关信息来生成结果。这种模式有时也被称为检索增强生成（Retrieval Augmented Generation，RAG）。

**目的**：幻觉问题（Hallucinations）仍然是当前 LLM 面临的一个重要挑战。简单来说，幻觉问题是指 LLM 在生成不正确、荒谬或者与事实不符的结果。此外，数据新鲜度（Data Freshness）也是 LLM 在生成结果时出现的另外一个问题，即 LLM 对于一些时效性比较强的问题可能给不出或者给出过时的答案。RALLM 通过检索外部相关信息的方式来增强 LLM 的生成结果是当前解决以上问题的一种流行方案。

传统的信息检索工具，比如 Google/Bing 这样的搜索引擎，只有检索能力（Retrieval-only），现在 LLM 通过预训练过程，将海量数据和知识嵌入到其巨大的模型参数中，具有记忆能力（Memory-only）。从这个角度看，检索增强 LLM 处于中间，将 LLM 和传统的信息检索相结合，通过一些信息检索技术将相关信息加载到 LLM 的工作内存（Working Memory）中，即 LLM 的上下文窗口（Context Window），亦即 LLM 单次生成时能接受的最大文本输入。



- 主题
    - 目的
    - 应用场景
        - 长尾知识
        - 私有数据
        - 数据新鲜度
        - 来源验证和可解释性
        - 对话场景提供记忆、state 等动态信息

# 应用场景

为什么要结合传统的信息检索系统来增强 LLM？换句话说，基于检索增强的 LLM 主要解决的问题和应用场景是什么？

## 主要解决问题

### 长尾知识

虽然当前 LLM 的训练数据量已经非常庞大，动辄几百 GB 级别的数据量，万亿级别的 token 数量，比如 GPT-3 的预训练数据使用了 3000 亿量级的 token，LLaMA 使用了 1.4 万亿量级的 token。训练数据的来源也十分丰富，比如维基百科、书籍、论坛、代码等。LLM 的模型参数量也十分巨大，从几十亿、百亿到千亿量级，但让 LLM 在有限的参数中记住所有知识或者信息是不现实的，训练数据的涵盖范围也是有限的，总会有一些长尾知识在训练数据中不能覆盖到。

对于一些相对通用和大众的知识，LLM 通常能生成比较准确的结果，而对于一些长尾知识，LLM 生成的回复通常并不可靠。ICML 会议上的这篇论文 [[Large Language Models Struggle to Learn Long-Tail Knowledge]](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/2211.08411) 就研究了 LLM 对基于事实的回答的准确性和预训练数据中相关领域文档数量的关系，发现有很强的相关性，即预训练数据中相关文档数量越多，LLM 对事实性问答的回复准确性就越高。从这个研究中可以得出一个简单的结论——LLM 对长尾知识的学习能力比较弱。

为了提升 LLM 对长尾知识的学习能力，除了在训练数据中加入更多的相关长尾知识，或者增大模型的参数量外（这两种方法确实都有一定的效果，但不经济，需要很大的训练数据量级和模型参数才能大幅度提升 LLM 对长尾知识的回复准确性），通过检索的方法把相关信息在 LLM 推断时作为上下文（Context）给出，既能达到一个比较好的回复准确性，也是一种比较经济的方式。

### 私有数据

通用 LLM 预训练阶段使用的大部分都是公开的数据，不包含私有数据，因此对于一些私有领域的知识是欠缺的。比如某个企业内部的规章制度等等。虽然可以在预训练阶段加入私有数据或者利用私有数据进行微调，但训练和迭代成本很高。此外，通过一些特定的攻击手法可以让 LLM 泄露训练数据，如果训练数据中包含一些私有ixnxi，则很可能会发生隐私信息泄露。

如果把私有数据作为一个外部数据库，让 LLM 在回答基于私有数据的问题时，直接从外部数据库中检索出相关信息，再结合检索出的相关信息进行回答。这样就不用通过预训练或者微调的方法让 LLM 在参数中记住私有知识，既节省了训练或者微调成本，也一定程度上避免了私有数据的泄露风险。

### 数据新鲜度

由于 LLM 中学习的知识来自于训练数据，虽然大部分知识的更新周期不会很快，但依然会有一些知识或者信息更新得很频繁。LLM 通过从预训练数据中学到的这部分信息就很容易过时。比如，GPT-4 模型使用的是截至 2021-09 的预训练数据，因此涉及这个日期之后的事件或者信息，它会拒绝回答或者给出的回复是过时或者不准确的。

如果把频繁更新的知识作为外部数据库，供 LLM 在必要的时候进行检索，就可以实现在不重新训练 LLM 的情况下对 LLM 的知识进行更新和拓展，从而解决 LLM 数据新鲜度的问题。

### 来源验证和可解释性

通常情况下，LLM 生成的输出不会给出其来源，比较难解释为什么会这么生成。而通过给 LLM 提供外部数据源，让其基于检索出的相关信息进行生成，就在生成的结果和信息来源之间建立了关联，因此生成的结果就可以追溯参考来源，可解释性和可控性就大大增强。即可以知道 LLM 是基于什么相关信息来生成的回复。利用检索来增强 LLM 的输出，其中很重要的一步是通过一些检索相关的技术从外部数据中找出相关信息片段，然后把相关信息片段作为上下文供 LLM 在生成回复时参考。
